<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 on Machine Learning 学习笔记</title>
    <link>https://kingye.me/study-ml/</link>
    <description>Recent content in 首页 on Machine Learning 学习笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://kingye.me/study-ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>基础</title>
      <link>https://kingye.me/study-ml/docs/appendix/interview/basic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/appendix/interview/basic/</guid>
      <description> 基础面试题 # </description>
    </item>
    <item>
      <title>进阶</title>
      <link>https://kingye.me/study-ml/docs/appendix/interview/advanced/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/appendix/interview/advanced/</guid>
      <description> 进阶面试题 # </description>
    </item>
    <item>
      <title>4.1 教程</title>
      <link>https://kingye.me/study-ml/docs/appendix/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/appendix/tutorial/</guid>
      <description>教程 # 基础 # 【视频】李宏毅 2021/2022 春机器学习课程 # 【视频】吴恩达机器学习系列课程 # 【视频】吴恩达深度学习 deeplearning.ai # 【视频】林轩田机器学习基石 # 【视频】机器学习技法（林轩田） # Fafa-DL/Lhy_Machine_Learning # 李宏毅 2021 春季机器学习课程课件及作业&#xA;microsoft/ML-For-Beginners # Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about Machine Learning.&#xA;Avik-Jain/100-Days-Of-ML-Code # MLEveryday/100-Days-Of-ML-Code # 机器学习 100 天&#xA;llSourcell/Learn_Machine_Learning_in_3_Months # This is the code for &amp;ldquo;Learn Machine Learning in 3 Months&amp;rdquo; by Siraj Raval on Youtube&#xA;FudanNLP/nlp-beginner # NLP-Beginner：自然语言处理入门练习</description>
    </item>
    <item>
      <title>4.3 关注项目</title>
      <link>https://kingye.me/study-ml/docs/appendix/attention/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/appendix/attention/</guid>
      <description>关注项目 # 机器学习 # tensorflow/tensorflow # scikit-learn/scikit-learn # scikit-learn: machine learning in Python https://scikit-learn.org&#xA;php-ai/php-ml # PHP-ML - Machine Learning library for PHP https://php-ml.org/&#xA;深度学习 # paddlepaddle/paddle # Tencent/ncnn # ncnn is a high-performance neural network inference framework optimized for the mobile platform&#xA;机器人 # gunthercox/ChatterBot # ChatterBot is a machine learning, conversational dialog engine for creating chat bots https://chatterbot.readthedocs.io</description>
    </item>
    <item>
      <title>AI Agent</title>
      <link>https://kingye.me/study-ml/docs/basic/lm/agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/lm/agent/</guid>
      <description> AI Agent # Significant-Gravitas/Auto-GPT geekan/MetaGPT reworkd/AgentGPT TransformerOptimus/SuperAGI </description>
    </item>
    <item>
      <title>HuggingFace</title>
      <link>https://kingye.me/study-ml/docs/basic/huggingface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/huggingface/</guid>
      <description>HuggingFace # 下载模型 # huggingface_hub # # 安装依赖 pip install huggingface_hub # 先在 shell 执行 export HF_ENDPOINT=https://hf-mirror.com from huggingface_hub import snapshot_download snapshot_download(repo_id=&amp;#39;THUDM/chatglm3-6b&amp;#39;, repo_type=&amp;#39;model&amp;#39;, local_dir=&amp;#39;./models/chatglm3-6b&amp;#39;, resume_download=True) Huggingface 镜像站 # https://hf-mirror.com/ # # 安装依赖 pip install -U huggingface_hub hf_transfer export HF_ENDPOINT=https://hf-mirror.com # 提高下载速度，推荐设置环境变量开启 hf_tranfer，官方的下载加速库 # 缺点是没有进度条 export HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download THUDM/chatglm3-6b --local-dir models/chatglm3-6b # 下载需要登录的模型（Gated Model） # 添加 --token hf_*** 参数，其中 hf_*** 是 access token，请在 https://huggingface.co/settings/tokens 获取 huggingface-cli download --token hf_*** THUDM/chatglm3-6b --local-dir models/chatglm3-6b aliendao # git-cloner/aliendao # 下载模型，带上 mirror 优先从镜像下载 python model_download.</description>
    </item>
    <item>
      <title>LLM</title>
      <link>https://kingye.me/study-ml/docs/basic/lm/llm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/lm/llm/</guid>
      <description>LLM（大型语言模型） # 大语言模型 (英语：large language model，LLM) 是一种语言模型，由具有许多参数（通常数十亿个权重或更多）的人工神经网络组成，使用自监督学习或半监督学习对大量未标记文本进行训练。大型语言模型在 2018 年左右出现，并在各种任务中表现出色。&#xA;图片来自：Foundation Large Language Model Stack&#xA;开源大语言模型 # meta-LLaMa OpenLLaMA: openlm-research/open_llama LLaMA (Large Language Model Meta AI) 7B meta-llama/Llama-2-7b meta-llama/Llama-2-7b-hf meta-llama/Llama-2-7b-chat meta-llama/Llama-2-7b-chat-hf 13B meta-llama/Llama-2-13b meta-llama/Llama-2-13b-hf meta-llama/Llama-2-13b-chat meta-llama/Llama-2-13b-chat-hf 70B meta-llama/Llama-2-70b meta-llama/Llama-2-70b-hf meta-llama/Llama-2-70b-chat meta-llama/Llama-2-70b-chat-hf tiiuae 7B tiiuae/falcon-7b-instruct tiiuae/falcon-7b 40B tiiuae/falcon-40b-instruct tiiuae/falcon-40b 180B tiiuae/falcon-180B tiiuae/falcon-180B-chat THUDM GLM: General Language Model 6B THUDM/chatglm3-6b-base THUDM/chatglm3-6b THUDM/chatglm3-6b-32k THUDM/chatglm2-6b THUDM/chatglm2-6b-int4 7B THUDM/agentlm-7b 10B THUDM/glm-10b-chinese bigscience 560m bigscience/bloom-560m 1B bigscience/bloom-1b7 7B bigscience/bloom-7b1 3B bigscience/bloom-3b 176B bigscience/bloom Baichuan 7B baichuan-inc/Baichuan2-7B-Base baichuan-inc/Baichuan2-7B-Chat baichuan-inc/Baichuan2-7B-Chat-4bits baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints baichuan-inc/Baichuan-7B 13B baichuan-inc/Baichuan-13B-Base baichuan-inc/Baichuan2-13B-Base baichuan-inc/Baichuan-13B-Chat baichuan-inc/Baichuan2-13B-Chat baichuan-inc/Baichuan2-13B-Chat-4bits 大模型应用工具 # langchain-ai/langchain run-llama/llama_index deepset-ai/haystack microsoft/TaskMatrix microsoft/semantic-kernel BERT # Bidirectional Encoder Representations from Transformers</description>
    </item>
    <item>
      <title>ONNX</title>
      <link>https://kingye.me/study-ml/docs/basic/onnx/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/onnx/</guid>
      <description> ONNX # Open Neural Network Exchange&#xA;开放神经网络交换&#xA;是微软和 Facebook 提出用来表示深度学习模型的开放格式 定义了一组和环境，平台均无关的标准格式，来增强各种 AI 模型的可交互性 无论你使用何种训练框架训练模型（比如 TensorFlow/Pytorch/OneFlow/Paddle），在训练完毕后你都可以将这些框架的模型统一转换为 ONNX 这种统一的格式进行存储 </description>
    </item>
    <item>
      <title>RAG</title>
      <link>https://kingye.me/study-ml/docs/basic/lm/rag/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/lm/rag/</guid>
      <description> RAG # RAG (Retrieval-Augmented Generation) 框架：&#xA;是一种结合才信息检索 Retrieval 和生成 Generation 的语言模型架构。&#xA;可以动态地从外部知识源检索信息，使用检索到的数据作为参考来组织答案。来提高模型在回答复杂问题时的准确性和深度。&#xA;RAG 工作过程分两个阶段：&#xA;知识构建阶段 文本分片清洗、文本向量化、存入向量数据库 检索应用阶段 用户输入查询、 用户问题向量化、向量检索、排序、生成答案 如果给大模型喂企业私有数据，做模型微调，也能实现同样的效果，为什么还要用 RAG 呢，我认为还要看场景：&#xA;私有数据存在一定频率的动态更新的； 需要给出引用原文的； 硬件资源（GPU）不是太充足的（即使用 RAG 也需要微调，但一次微调处处可用，远比每个企业私有库微调一个模型成本低的多）； </description>
    </item>
    <item>
      <title>教程</title>
      <link>https://kingye.me/study-ml/docs/basic/ml/dl/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kingye.me/study-ml/docs/basic/ml/dl/tutorial/</guid>
      <description> 教程 # 基础 # 《深度学习》(花书) # MingchaoZhu/DeepLearning # Python for《Deep Learning》，该书为《深度学习》(花书) 数学推导、原理剖析与源码级别代码实现&#xA;进阶 # </description>
    </item>
  </channel>
</rss>
