[{"id":0,"href":"/study-ml/docs/basic/","title":"第一部分 基础入门","section":"Docs","content":" 算法训练监控 # wandb/wandb Weights \u0026amp; Biases tensorflow/tensorboard fossasia/visdom IDSIA/sacred guildai/guildai neptune-ai/neptune-client Unbabel/COMET "},{"id":1,"href":"/study-ml/docs/appendix/interview/basic/","title":"基础","section":"4.2 面试题","content":" 基础面试题 # "},{"id":2,"href":"/study-ml/docs/appendix/interview/advanced/","title":"进阶","section":"4.2 面试题","content":" 进阶面试题 # "},{"id":3,"href":"/study-ml/docs/appendix/tutorial/","title":"4.1 教程","section":"第四部分 附录","content":" 教程 # 基础 # 【视频】李宏毅 2021/2022 春机器学习课程 # 【视频】吴恩达机器学习系列课程 # 【视频】吴恩达深度学习 deeplearning.ai # 【视频】林轩田机器学习基石 # 【视频】机器学习技法（林轩田） # Fafa-DL/Lhy_Machine_Learning # 李宏毅 2021 春季机器学习课程课件及作业\nmicrosoft/ML-For-Beginners # Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about Machine Learning.\nAvik-Jain/100-Days-Of-ML-Code # MLEveryday/100-Days-Of-ML-Code # 机器学习 100 天\nllSourcell/Learn_Machine_Learning_in_3_Months # This is the code for \u0026ldquo;Learn Machine Learning in 3 Months\u0026rdquo; by Siraj Raval on Youtube\nFudanNLP/nlp-beginner # NLP-Beginner：自然语言处理入门练习\nboyu-ai/Hands-on-RL # 动手学强化学习\nboyu-ai/Hands-on-ML # 动手学机器学习\nboyu-ai/Hands-on-NLP # 动手学自然语言处理\n进阶 # dive into deep learning # d2l-ai/d2l-en 动手学深度学习 # d2l-ai/d2l-zh pytorch 版本 将《动手学深度学习》(Dive into Deep Learning) 原书中的 MXNet 实现改为 PyTorch 实现 # ShusenTang/Dive-into-DL-PyTorch 将《动手学深度学习》(Dive into Deep Learning)原书中的 MXNet 实现改为 TensorFlow 2.0 实现 # TrickyGo/Dive-into-DL-TensorFlow2.0 动手学强化学习 # boyu-ai/Hands-on-RL 手写实现李航《统计学习方法》书中全部算法 # dod-o/statistical-learning-method_code 机器学习白板推导系列 # shuhuai007/machine-learning-session 【视频】【机器学习】【白板推导系列】【合集 1 ～ 23】\n机器学习白板系列 笔记 # tsyw/MachineLearningNotes Bilibili - 机器学习白板系列\njosephmisiti/awesome-machine-learning # ZuzooVn/machine-learning-for-software-engineers # A complete daily plan for studying to become a machine learning engineer.\n自上而下的学习路线：软件工程师的机器学习\nageron/handson-ml # A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\nfighting41love/funNLP # NLP 民工的乐园：几乎最全的中文 NLP 资源库\neriklindernoren/ML-From-Scratch # Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.\ntrekhleb/homemade-machine-learning # Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained.\nkailashahirwar/cheatsheets-ai # Essential Cheat Sheets for deep learning and machine learning researchers\nhttps://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5\nhttps://aicheatsheets.com\nrasbt/python-machine-learning-book # The \u0026ldquo;Python Machine Learning (1st edition)\u0026rdquo; book code repository and info resource\nafshinea/stanford-cs-229-machine-learning # !Github stars\nVIP cheatsheets for Stanford\u0026rsquo;s CS 229 Machine Learning https://stanford.edu/~shervine/teaching/cs-229/\nujjwalkarn/Machine-Learning-Tutorials # machine learning and deep learning tutorials, articles and other resources http://ujjwalkarn.github.io/Machine-Learning-Tutorials/\njanishar/mit-deep-learning-book-pdf # MIT Deep Learning Book in PDF format (complete and parts) by Ian Goodfellow, Yoshua Bengio and Aaron Courville\n斯坦福大学 2014（吴恩达）机器学习教程中文笔记 # fengdu78/Coursera-ML-AndrewNg-Notes 进阶 # christophm/interpretable-ml-book # Book about interpretable machine learning https://christophm.github.io/interpretable-ml-book/\nmingchaozhu/interpretablemlbook # 该书为《Interpretable Machine Learning》中文版。该书原作者是 Christoph Molnar，他是一名统计学家和机器学习者 @christophM。该书的项目 地址，这是一个很棒的工作。你可以在 releases 中下载本书英文版 pdf。\n我是 朱明超，同样，我也是一名机器学习者。关于此书的译本，我在翻译后进行了校正。如果你在英文原书中看到某些表述问题，可以参考我在中文书里的描述。当然，由于英文原书是较早前出版的，本书并不是完全基于英文书，作者 Christoph Molnar 在《Interpretable Machine Learning》的 网页版 中对内容不断填充，所以中文版的翻译主要基于网页版 (内容会多于英文书)。你可以在 releases 中下载本书中文版 pdf。\nhangtwenty/dive-into-machine-learning # Dive into Machine Learning with Python Jupyter notebook and scikit-learn! http://hangtwenty.github.io/dive-into-machine-learning/\nRedditSota/state-of-the-art-result-for-machine-learning-problems # This repository provides state of the art (SoTA) results for all machine learning problems.\nscutan90/DeepLearning-500-questions # 深度学习 500 问，以问答形式对常用的概率知识、线性代数、机器学习、深度学习、计算机视觉等热点问题进行阐述\nrushter/MLAlgorithms # Minimal and clean examples of machine learning algorithms implementations\n"},{"id":4,"href":"/study-ml/docs/basic/ml/frame/tensorflow/","title":"Tensorflow","section":"AI 框架","content":" Tensorflow # tensorflow/tensorflow 教程 # lyhue1991/eat_tensorflow2_in_30_days # tensorflow/models # Models and examples built with TensorFlow\naymericdamien/TensorFlow-Examples # TensorFlow Tutorial and Examples for Beginners (support TF v1 \u0026amp; v2)\n"},{"id":5,"href":"/study-ml/docs/appendix/interview/","title":"4.2 面试题","section":"第四部分 附录","content":" 面试题 # 基础题 # 进阶题 # "},{"id":6,"href":"/study-ml/docs/basic/ml/frame/paddle/","title":"PaddlePaddle","section":"AI 框架","content":" PaddlePaddle # paddlepaddle/paddle PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习 \u0026amp; 机器学习高性能单机、分布式训练和跨平台部署） http://www.paddlepaddle.org/\n"},{"id":7,"href":"/study-ml/docs/basic/ml/dl/","title":"深度学习","section":"Ml","content":" 深度学习 # "},{"id":8,"href":"/study-ml/docs/appendix/attention/","title":"4.3 关注项目","section":"第四部分 附录","content":" 关注项目 # 机器学习 # scikit-learn/scikit-learn # scikit-learn: machine learning in Python https://scikit-learn.org\nphp-ai/php-ml # PHP-ML - Machine Learning library for PHP https://php-ml.org/\n深度学习 # pytorch/pytorch BVLC/caffe tensorflow/tensorflow paddlepaddle/paddle microsoft/CNTK Tencent/ncnn ncnn is a high-performance neural network inference framework optimized for the mobile platform Oneflow-Inc/oneflow 机器人 # gunthercox/ChatterBot # ChatterBot is a machine learning, conversational dialog engine for creating chat bots https://chatterbot.readthedocs.io\n"},{"id":9,"href":"/study-ml/docs/basic/llm/agent/","title":"AI Agent","section":"LM","content":" AI Agent # Significant-Gravitas/Auto-GPT geekan/MetaGPT reworkd/AgentGPT TransformerOptimus/SuperAGI "},{"id":10,"href":"/study-ml/docs/basic/ml/frame/","title":"AI 框架","section":"Ml","content":" AI 框架 # pytorch 框架 # pytorch/pytorch PyTorch is a Python package that provides two high-level features: Tensor computation (like NumPy) with strong GPU acceleration Deep neural networks built on a tape-based autograd system tinygrad/tinygrad tinygrad: For something between PyTorch and karpathy/micrograd. karpathy/micrograd A tiny Autograd engine "},{"id":11,"href":"/study-ml/docs/basic/huggingface/","title":"HuggingFace","section":"第一部分 基础入门","content":" HuggingFace # 下载模型 # huggingface_hub # # 安装依赖 pip install huggingface_hub # 先在 shell 执行 export HF_ENDPOINT=https://hf-mirror.com from huggingface_hub import snapshot_download snapshot_download(repo_id=\u0026#39;THUDM/chatglm3-6b\u0026#39;, repo_type=\u0026#39;model\u0026#39;, local_dir=\u0026#39;./models/chatglm3-6b\u0026#39;, resume_download=True) Huggingface 镜像站 # https://hf-mirror.com/ # # 安装依赖 pip install -U huggingface_hub hf_transfer export HF_ENDPOINT=https://hf-mirror.com # 提高下载速度，推荐设置环境变量开启 hf_tranfer，官方的下载加速库 # 缺点是没有进度条 export HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download THUDM/chatglm3-6b --local-dir models/chatglm3-6b # 下载需要登录的模型（Gated Model） # 添加 --token hf_*** 参数，其中 hf_*** 是 access token，请在 https://huggingface.co/settings/tokens 获取 huggingface-cli download --token hf_*** THUDM/chatglm3-6b --local-dir models/chatglm3-6b aliendao # git-cloner/aliendao # 下载模型，带上 mirror 优先从镜像下载 python model_download.py --mirror --repo_id 模型ID # 举例 python model_download.py --mirror --repo_id THUDM/chatglm2-6b # 下载数据集 python model_download.py --mirror --repo_id 数据集ID --repo_type dataset # 举例 python model_download.py --mirror --repo_id THUDM/chatglm2-6b --repo_type dataset 阿里魔搭社区 # from modelscope import snapshot_download model_dir = snapshot_download(\u0026#39;ZhipuAI/chatglm3-6b\u0026#39;, cache_dir=\u0026#39;./models\u0026#39;, revision=\u0026#39;v1.0.0\u0026#39;) "},{"id":12,"href":"/study-ml/docs/basic/llm/llm/","title":"LLM","section":"LM","content":" LLM（大型语言模型） # 大语言模型 (英语：large language model，LLM) 是一种语言模型，由具有许多参数（通常数十亿个权重或更多）的人工神经网络组成，使用自监督学习或半监督学习对大量未标记文本进行训练。大型语言模型在 2018 年左右出现，并在各种任务中表现出色。\n图片来自：Foundation Large Language Model Stack\n开源大语言模型 # meta-LLaMa OpenLLaMA: openlm-research/open_llama LLaMA (Large Language Model Meta AI) 7B meta-llama/Llama-2-7b meta-llama/Llama-2-7b-hf meta-llama/Llama-2-7b-chat meta-llama/Llama-2-7b-chat-hf 13B meta-llama/Llama-2-13b meta-llama/Llama-2-13b-hf meta-llama/Llama-2-13b-chat meta-llama/Llama-2-13b-chat-hf 70B meta-llama/Llama-2-70b meta-llama/Llama-2-70b-hf meta-llama/Llama-2-70b-chat meta-llama/Llama-2-70b-chat-hf tiiuae 7B tiiuae/falcon-7b-instruct tiiuae/falcon-7b 40B tiiuae/falcon-40b-instruct tiiuae/falcon-40b 180B tiiuae/falcon-180B tiiuae/falcon-180B-chat THUDM GLM: General Language Model 6B THUDM/chatglm3-6b-base THUDM/chatglm3-6b THUDM/chatglm3-6b-32k THUDM/chatglm2-6b THUDM/chatglm2-6b-int4 7B THUDM/agentlm-7b 10B THUDM/glm-10b-chinese bigscience 560m bigscience/bloom-560m 1B bigscience/bloom-1b7 7B bigscience/bloom-7b1 3B bigscience/bloom-3b 176B bigscience/bloom Baichuan 7B baichuan-inc/Baichuan2-7B-Base baichuan-inc/Baichuan2-7B-Chat baichuan-inc/Baichuan2-7B-Chat-4bits baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints baichuan-inc/Baichuan-7B 13B baichuan-inc/Baichuan-13B-Base baichuan-inc/Baichuan2-13B-Base baichuan-inc/Baichuan-13B-Chat baichuan-inc/Baichuan2-13B-Chat baichuan-inc/Baichuan2-13B-Chat-4bits 大模型应用工具 # langchain-ai/langchain run-llama/llama_index deepset-ai/haystack microsoft/TaskMatrix microsoft/semantic-kernel BERT # Bidirectional Encoder Representations from Transformers\ngoogle-research/bert 微调 # 预训练大语言模型的三种微调技术总结：\nfine-tuning Fine-tuning 的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。 parameter-efficient fine-tuning PEFT 在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。 3 种技术 蒸馏(distillation)，它由 Hinton 等人于 2015 年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。 适配器训练(adapter training)，它由 Houlsby 等人于 2019 年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。 渐进收缩(progressive shrinking)，它由 Kaplan 等人于 2020 年引入。这种技术涉及在 fine-tuning 期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。 prompt-tuning 只修改模型的输入，不需要大量计算资源 参考：预训练大语言模型的三种微调技术总结：fine-tuning、parameter-efficient fine-tuning 和 prompt-tuning\nGemini # 谷歌官宣 Bard 更名 Gemini，是大模型也是产品，集聊天助手、搜索引擎于一身，将带来哪些影响？\nQwen # QwenLM/Qwen Qwen 不仅仅是一个语言模型，而是一个致力于实现通用人工智能（AGI）的项目，目前包含了大型语言模型（LLM）和大型多模态模型（LMM）。下图展示了 Qwen 的主要组成部分:\n在这里，“Qwen” 指的是基础语言模型，而 “Qwen-Chat” 则指的是通过后训练技术如 SFT（有监督微调）和 RLHF（强化学习人类反馈）训练的聊天模型。\n我们还有提供了专门针对特定领域和任务的模型，例如用于编程的 “Code-Qwen” 和用于数学的 “Math-Qwen”。\n大型语言模型（LLM）可以通过模态对齐扩展到多模态，因此我们有视觉-语言模型 “Qwen-VL” 以及音频-语言模型 “Qwen-Audio” 。\nRLHF（Reinforcement Learning from Human Feedback） 大模型，如 GPT（Generative Pretrained Transformer）或 BERT（Bidirectional Encoder Representations from Transformers），是基于变换器（Transformer）架构的深度学习模型。它们通常用于自然语言处理任务。让我来详细解释这些模型的工作过程：\n接收 Prompt： 当模型接收到一段文本（称为“prompt”），它首先需要理解和处理这段文本。在处理前，通常会先进行分词（将句子分解成单词或子词单元）。 转换为嵌入 (Embedding)： 分词后，模型将每个词或子词转换为一个嵌入。嵌入是一种高维空间中的向量，这些向量捕捉了词的语义和语法属性。嵌入可以通过查找预训练的嵌入矩阵来获得，这个矩阵将每个词映射到一个固定长度的向量。 嵌入（Embedding）是将词、短语或者整个文档从原始表示（通常是文本形式的）转换为实数向量的过程。在自然语言处理（NLP）中，嵌入向量通常捕捉单词的语义意义和在语境中的用法。这些嵌入向量让计算机能够理解词语，并对其进行数学运算。嵌入向量是深度学习模型能够处理文本数据的关键。 注意力计算和前馈计算： 之后，模型通过其多层结构进行计算，每一层都包含两个主要部分： 自注意力机制（Self-Attention）： 这个机制让模型能够在处理每个词时考虑到句子中的其他词，从而理解词与词之间的关系。 前馈网络（Feed-Forward Neural Network）： 在自注意力之后，每个词的表示将通过一个前馈网络，这个网络通常包含几个线性变换和非线性激活函数。 生成 Logits： 每一层的输出会传递到下一层，直到最后一层。在最后一层，模型生成一个 logit 向量，其长度等于词汇表的大小。每个 logit 代表模型预测下一个词是词汇表中每个词的非规范化概率。 概率分布： 最终，logits 通过一个激活函数（如 SoftMax）转换为概率分布。SoftMax 函数可以确保所有可能词的预测概率加起来等于 1。 这个概率分布反映了在给定前面的文本后，模型预测下一个词是词汇表中任何一个词的可能性。 生成文本： 根据这个概率分布，模型会选择概率最高的词作为下一个词，或者根据概率分布随机抽取一个词，从而生成文本。 整个过程涉及大量的矩阵计算，通常在 GPU 或 TPU 上执行以加速这些操作。这种模型的强大之处在于其能够理解和生成复杂的语言结构，这使得它们在许多自然语言任务中都非常有效。\n嵌入 (Embedding) 是高维空间中的点，这些点代表了词汇表中的词。它们通常通过训练得到，以便具有这样的属性：语义或语法上相似的词在嵌入空间中彼此靠近。这里有一些关于嵌入的关键点：\n维度： 嵌入向量有固定的维度，这个维度通常远小于词汇表的大小。例如，你可能有一个由数百万个词组成的词汇表，但每个词的嵌入向量可能只有几百维。\n训练过程： 在预训练的模型（如 word2vec 或 GloVe）中，嵌入向量是通过在大量文本上学习得到的，这些模型会调整嵌入向量，使得在文本中共现的词在嵌入空间中更接近。\n上下文敏感度： 传统的嵌入模型（如 word2vec 和 GloVe）生成的是静态嵌入，这意味着对于词汇表中的每个词，它总是有同样的嵌入向量，不管它出现在什么上下文中。而上下文相关的嵌入（如 BERT 中的嵌入）能够根据词出现的上下文生成不同的向量。\n嵌入的使用： 嵌入向量用于初始化深度学习模型中的权重，随着模型在特定任务上的训练，它们可能会进行微调。例如，在 GPT 这样的模型中，嵌入层是模型的第一层，它将输入的文本转换为向量，这些向量随后通过模型的其它层进行处理。\n举一个简单的比喻，你可以想象每个词都是一点颜料，而嵌入就像是把这些点颜料滴在一个巨大的白纸上。在这张白纸上，相似的颜色（词）会更接近，而不同的颜色（词）会更远。深度学习模型通过这样的方式“看”文本，并了解不同词和短语之间的关系。\n“Logit”这个词来源于 logistic regression（逻辑回归）中，是“logistic unit”的缩写。在数学上，logit 函数通常指的是一个特定的函数，它把一个概率值（介于 0 和 1 之间的值）映射到负无穷到正无穷的范围内。这个函数是逻辑函数的逆函数。但在深度学习和机器学习的上下文中，\u0026ldquo;logit\u0026quot;一词有时被用来指代模型的原始输出，即还没有经过 softmax 或其他归一化函数转换成概率之前的值。\n在深度学习中，当我们讨论模型（尤其是分类模型）的输出时，模型通常会输出一个向量，这个向量的每个元素对应于一个类别的得分或者说是“原始”概率——这就是 logit。这些得分后来通常会通过一个 softmax 函数转换成概率分布，softmax 函数能够确保所有输出值的总和为 1，使其可以被解释为概率。\n"},{"id":13,"href":"/study-ml/docs/basic/nlp/","title":"NLP","section":"第一部分 基础入门","content":" NLP # NLP 的范式演进历程大体经历了这样四个阶段：\n特征工程 → 深度学习 → 预训练+精调 → Prompt\n预训练+精调范式：让预训练模型（PLM）去适应下游任务 Prompt 范式：让下游任务适应预训练模型（PLM） Prompt：将下游任务的输入输出形式改造成预训练任务中的形式，即 MLM (Masked Language Model) 的形式 "},{"id":14,"href":"/study-ml/docs/basic/onnx/","title":"ONNX","section":"第一部分 基础入门","content":" ONNX # Open Neural Network Exchange\n开放神经网络交换\n是微软和 Facebook 提出用来表示深度学习模型的开放格式 定义了一组和环境，平台均无关的标准格式，来增强各种 AI 模型的可交互性 无论你使用何种训练框架训练模型（比如 TensorFlow/Pytorch/OneFlow/Paddle），在训练完毕后你都可以将这些框架的模型统一转换为 ONNX 这种统一的格式进行存储 "},{"id":15,"href":"/study-ml/docs/basic/ml/frame/pytorch/","title":"PyTorch","section":"AI 框架","content":" PyTorch # pytorch/pytorch PyTorch is a Python package that provides two high-level features:\nTensor computation (like NumPy) with strong GPU acceleration Deep neural networks built on a tape-based autograd system "},{"id":16,"href":"/study-ml/docs/basic/llm/rag/","title":"RAG","section":"LM","content":" RAG # RAG (Retrieval-Augmented Generation) 框架：\n是一种结合才信息检索 Retrieval 和生成 Generation 的语言模型架构。\n可以动态地从外部知识源检索信息，使用检索到的数据作为参考来组织答案。来提高模型在回答复杂问题时的准确性和深度。\nRAG 工作过程分两个阶段：\n知识构建阶段 文本分片清洗、文本向量化、存入向量数据库 检索应用阶段 用户输入查询、 用户问题向量化、向量检索、排序、生成答案 如果给大模型喂企业私有数据，做模型微调，也能实现同样的效果，为什么还要用 RAG 呢，我认为还要看场景：\n私有数据存在一定频率的动态更新的； 需要给出引用原文的； 硬件资源（GPU）不是太充足的（即使用 RAG 也需要微调，但一次微调处处可用，远比每个企业私有库微调一个模型成本低的多）； 开源框架 # infiniflow/ragflow langgenius/dify labring/FastGPT netease-youdao/QAnything eosphoros-ai/DB-GPT "},{"id":17,"href":"/study-ml/docs/basic/llm/tutorials/","title":"教程","section":"LM","content":" 教程 # jingyaogong/minimind DLLXW/baby-llama2-chinese charent/ChatLM-mini-Chinese wdndev/tiny-llm-zh Tongjilibo/build_MiniLLM_from_scratch AI-Study-Han/Zero-Chatgpt "},{"id":18,"href":"/study-ml/docs/advanced/llm/","title":"LLM","section":"第二部分 进阶实战","content":" LLM（大型语言模型） # "},{"id":19,"href":"/study-ml/docs/basic/llm/","title":"LM","section":"第一部分 基础入门","content":" Large Model（大模型） # cv 大模型 # facebookresearch/segment-anything UX-Decoder/Segment-Everything-Everywhere-All-At-Once SEEM: Segment Everything Everywhere All at Once baaivision/Painter Painter \u0026amp; SegGPT Series: Vision Foundation Models from BAAI 大模型推理框架 # ggerganov/llama.cpp ollama/ollama vllm-project/vllm sgl-project/sglang NVIDIA/TensorRT-LLM NVIDIA/FasterTransformer 废弃了，改用 TensorRT-LLM deepspeedai/DeepSpeed-MII microsoft/onnxruntime huggingface/text-generation-inference TGI ModelTC/lightllm 教程 # rasbt/LLMs-from-scratch "},{"id":20,"href":"/study-ml/docs/basic/llm/sd/","title":"Stable Diffusion","section":"LM","content":" Stable Diffusion # Stability-AI/stablediffusion CompVis/stable-diffusion AUTOMATIC1111/stable-diffusion-webui comfyanonymous/ComfyUI huggingface/diffusers invoke-ai/InvokeAI mudler/LocalAI Sanster/IOPaint "},{"id":21,"href":"/study-ml/docs/basic/ml/dl/tutorial/","title":"教程","section":"深度学习","content":" 教程 # 基础 # 《深度学习》(花书) # MingchaoZhu/DeepLearning # Python for《Deep Learning》，该书为《深度学习》(花书) 数学推导、原理剖析与源码级别代码实现\n进阶 # "}]