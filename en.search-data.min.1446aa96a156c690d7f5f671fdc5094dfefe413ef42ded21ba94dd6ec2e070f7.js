'use strict';(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/study-ml/docs/appendix/interview/basic/",title:"基础",section:"4.2 面试题",content:"基础面试题 #  "}),e.add({id:1,href:"/study-ml/docs/appendix/interview/advanced/",title:"进阶",section:"4.2 面试题",content:"进阶面试题 #  "}),e.add({id:2,href:"/study-ml/docs/appendix/tutorial/",title:"4.1 教程",section:"第四部分 附录",content:"教程 #  基础 #  【视频】李宏毅 2021/2022 春机器学习课程 #  【视频】吴恩达机器学习系列课程 #  【视频】吴恩达深度学习 deeplearning.ai #  【视频】林轩田机器学习基石 #  【视频】机器学习技法（林轩田） #  Fafa-DL/Lhy_Machine_Learning #  李宏毅 2021 春季机器学习课程课件及作业\nmicrosoft/ML-For-Beginners #  Azure Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about Machine Learning.\nAvik-Jain/100-Days-Of-ML-Code #  MLEveryday/100-Days-Of-ML-Code #  机器学习 100 天\nllSourcell/Learn_Machine_Learning_in_3_Months #  This is the code for \u0026ldquo;Learn Machine Learning in 3 Months\u0026rdquo; by Siraj Raval on Youtube\nFudanNLP/nlp-beginner #  NLP-Beginner：自然语言处理入门练习\n 进阶 #  dive into deep learning #  d2l-ai/d2l-en 动手学深度学习 #  d2l-ai/d2l-zh 将《动手学深度学习》(Dive into Deep Learning) 原书中的 MXNet 实现改为 PyTorch 实现 #  ShusenTang/Dive-into-DL-PyTorch 将《动手学深度学习》(Dive into Deep Learning)原书中的 MXNet 实现改为 TensorFlow 2.0 实现 #  TrickyGo/Dive-into-DL-TensorFlow2.0  动手学强化学习 #  boyu-ai/Hands-on-RL  手写实现李航《统计学习方法》书中全部算法 #  dod-o/statistical-learning-method_code  机器学习白板推导系列 #  shuhuai007/machine-learning-session 【视频】【机器学习】【白板推导系列】【合集 1 ～ 23】\n机器学习白板系列 笔记 #  tsyw/MachineLearningNotes Bilibili - 机器学习白板系列\n josephmisiti/awesome-machine-learning #   ZuzooVn/machine-learning-for-software-engineers #  A complete daily plan for studying to become a machine learning engineer.\n自上而下的学习路线：软件工程师的机器学习\n ageron/handson-ml #  A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\n fighting41love/funNLP #  NLP 民工的乐园：几乎最全的中文 NLP 资源库\n eriklindernoren/ML-From-Scratch #  Machine Learning From Scratch. Bare bones NumPy implementations of machine learning models and algorithms with a focus on accessibility. Aims to cover everything from linear regression to deep learning.\n trekhleb/homemade-machine-learning #  Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained.\n kailashahirwar/cheatsheets-ai #  Essential Cheat Sheets for deep learning and machine learning researchers\nhttps://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5\nhttps://aicheatsheets.com\n rasbt/python-machine-learning-book #  The \u0026ldquo;Python Machine Learning (1st edition)\u0026rdquo; book code repository and info resource\n afshinea/stanford-cs-229-machine-learning #  !Github stars\nVIP cheatsheets for Stanford\u0026rsquo;s CS 229 Machine Learning https://stanford.edu/~shervine/teaching/cs-229/\n ujjwalkarn/Machine-Learning-Tutorials #  machine learning and deep learning tutorials, articles and other resources http://ujjwalkarn.github.io/Machine-Learning-Tutorials/\n janishar/mit-deep-learning-book-pdf #  MIT Deep Learning Book in PDF format (complete and parts) by Ian Goodfellow, Yoshua Bengio and Aaron Courville\n斯坦福大学 2014（吴恩达）机器学习教程中文笔记 #  fengdu78/Coursera-ML-AndrewNg-Notes  进阶 #  christophm/interpretable-ml-book #  Book about interpretable machine learning https://christophm.github.io/interpretable-ml-book/\nmingchaozhu/interpretablemlbook #  该书为《Interpretable Machine Learning》中文版。该书原作者是 Christoph Molnar，他是一名统计学家和机器学习者 @christophM。该书的项目 地址，这是一个很棒的工作。你可以在 releases 中下载本书英文版 pdf。\n我是 朱明超，同样，我也是一名机器学习者。关于此书的译本，我在翻译后进行了校正。如果你在英文原书中看到某些表述问题，可以参考我在中文书里的描述。当然，由于英文原书是较早前出版的，本书并不是完全基于英文书，作者 Christoph Molnar 在《Interpretable Machine Learning》的 网页版 中对内容不断填充，所以中文版的翻译主要基于网页版 (内容会多于英文书)。你可以在 releases 中下载本书中文版 pdf。\n hangtwenty/dive-into-machine-learning #  Dive into Machine Learning with Python Jupyter notebook and scikit-learn! http://hangtwenty.github.io/dive-into-machine-learning/\n RedditSota/state-of-the-art-result-for-machine-learning-problems #  This repository provides state of the art (SoTA) results for all machine learning problems.\n scutan90/DeepLearning-500-questions #  深度学习 500 问，以问答形式对常用的概率知识、线性代数、机器学习、深度学习、计算机视觉等热点问题进行阐述\nrushter/MLAlgorithms #  Minimal and clean examples of machine learning algorithms implementations\n "}),e.add({id:3,href:"/study-ml/docs/basic/ml/frame/tensorflow/",title:"Tensorflow",section:"AI 框架",content:"Tensorflow #  tensorflow/tensorflow 教程 #  lyhue1991/eat_tensorflow2_in_30_days #  tensorflow/models #  Models and examples built with TensorFlow\naymericdamien/TensorFlow-Examples #  TensorFlow Tutorial and Examples for Beginners (support TF v1 \u0026amp; v2)\n"}),e.add({id:4,href:"/study-ml/docs/appendix/interview/",title:"4.2 面试题",section:"第四部分 附录",content:"面试题 #  基础题 #  进阶题 #  "}),e.add({id:5,href:"/study-ml/docs/basic/ml/frame/paddle/",title:"PaddlePaddle",section:"AI 框架",content:"PaddlePaddle #  paddlepaddle/paddle PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice （『飞桨』核心框架，深度学习 \u0026amp; 机器学习高性能单机、分布式训练和跨平台部署） http://www.paddlepaddle.org/\n"}),e.add({id:6,href:"/study-ml/docs/basic/ml/dl/",title:"深度学习",section:"第一部分 基础入门",content:"深度学习 #  "}),e.add({id:7,href:"/study-ml/docs/appendix/attention/",title:"4.3 关注项目",section:"第四部分 附录",content:"关注项目 #  机器学习 #  tensorflow/tensorflow #  scikit-learn/scikit-learn #  scikit-learn: machine learning in Python https://scikit-learn.org\nphp-ai/php-ml #  PHP-ML - Machine Learning library for PHP https://php-ml.org/\n 深度学习 #  paddlepaddle/paddle #  Tencent/ncnn #  ncnn is a high-performance neural network inference framework optimized for the mobile platform\n 机器人 #  gunthercox/ChatterBot #  ChatterBot is a machine learning, conversational dialog engine for creating chat bots https://chatterbot.readthedocs.io\n"}),e.add({id:8,href:"/study-ml/docs/basic/ml/frame/",title:"AI 框架",section:"第一部分 基础入门",content:"AI 框架 #  "}),e.add({id:9,href:"/study-ml/docs/basic/huggingface/",title:"HuggingFace",section:"第一部分 基础入门",content:"HuggingFace #  下载模型 #  huggingface_hub #  # 安装依赖 pip install huggingface_hub  # 先在 shell 执行 export HF_ENDPOINT=https://hf-mirror.com from huggingface_hub import snapshot_download  snapshot_download(repo_id=\u0026#39;THUDM/chatglm3-6b\u0026#39;,  repo_type=\u0026#39;model\u0026#39;,  local_dir=\u0026#39;./models/chatglm3-6b\u0026#39;,  resume_download=True) Huggingface 镜像站 #  https://hf-mirror.com/ #  # 安装依赖 pip install -U huggingface_hub hf_transfer  export HF_ENDPOINT=https://hf-mirror.com  # 提高下载速度，推荐设置环境变量开启 hf_tranfer，官方的下载加速库 # 缺点是没有进度条 export HF_HUB_ENABLE_HF_TRANSFER=1  huggingface-cli download --resume-download THUDM/chatglm3-6b --local-dir models/chatglm3-6b  # 下载需要登录的模型（Gated Model） # 添加 --token hf_*** 参数，其中 hf_*** 是 access token，请在 https://huggingface.co/settings/tokens 获取 huggingface-cli download --token hf_*** --resume-download THUDM/chatglm3-6b --local-dir models/chatglm3-6b aliendao #  git-cloner/aliendao # 下载模型，带上 mirror 优先从镜像下载 python model_download.py --mirror --repo_id 模型ID # 举例 python model_download.py --mirror --repo_id THUDM/chatglm2-6b # 下载数据集 python model_download.py --mirror --repo_id 数据集ID --repo_type dataset # 举例 python model_download.py --mirror --repo_id THUDM/chatglm2-6b --repo_type dataset 阿里魔搭社区 #  from modelscope import snapshot_download  model_dir = snapshot_download(\u0026#39;ZhipuAI/chatglm3-6b\u0026#39;,  cache_dir=\u0026#39;./models\u0026#39;,  revision=\u0026#39;v1.0.0\u0026#39;) "}),e.add({id:10,href:"/study-ml/docs/basic/lm/llm/",title:"LLM",section:"LM",content:"LLM（大型语言模型） #  大语言模型 (英语：large language model，LLM) 是一种语言模型，由具有许多参数（通常数十亿个权重或更多）的人工神经网络组成，使用自监督学习或半监督学习对大量未标记文本进行训练。大型语言模型在 2018 年左右出现，并在各种任务中表现出色。\n开源大语言模型 #   meta-LLaMa  OpenLLaMA: openlm-research/open_llama  LLaMA (Large Language Model Meta AI) 7B  meta-llama/Llama-2-7b meta-llama/Llama-2-7b-hf meta-llama/Llama-2-7b-chat meta-llama/Llama-2-7b-chat-hf   13B  meta-llama/Llama-2-13b meta-llama/Llama-2-13b-hf meta-llama/Llama-2-13b-chat meta-llama/Llama-2-13b-chat-hf   70B  meta-llama/Llama-2-70b meta-llama/Llama-2-70b-hf meta-llama/Llama-2-70b-chat meta-llama/Llama-2-70b-chat-hf     tiiuae  7B  tiiuae/falcon-7b-instruct tiiuae/falcon-7b   40B  tiiuae/falcon-40b-instruct tiiuae/falcon-40b   180B  tiiuae/falcon-180B tiiuae/falcon-180B-chat     THUDM  GLM: General Language Model 6B  THUDM/chatglm3-6b-base THUDM/chatglm3-6b THUDM/chatglm3-6b-32k THUDM/chatglm2-6b THUDM/chatglm2-6b-int4   7B  THUDM/agentlm-7b   10B  THUDM/glm-10b-chinese     bigscience  560m  bigscience/bloom-560m   1B  bigscience/bloom-1b7   7B  bigscience/bloom-7b1   3B  bigscience/bloom-3b   176B  bigscience/bloom     Baichuan  7B  baichuan-inc/Baichuan2-7B-Base baichuan-inc/Baichuan2-7B-Chat baichuan-inc/Baichuan2-7B-Chat-4bits baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints baichuan-inc/Baichuan-7B   13B  baichuan-inc/Baichuan-13B-Base baichuan-inc/Baichuan2-13B-Base baichuan-inc/Baichuan-13B-Chat baichuan-inc/Baichuan2-13B-Chat baichuan-inc/Baichuan2-13B-Chat-4bits       大模型应用工具 #   langchain-ai/langchain  microsoft/TaskMatrix  microsoft/semantic-kernel  Significant-Gravitas/Auto-GPT  reworkd/AgentGPT    BERT #  Bidirectional Encoder Representations from Transformers\ngoogle-research/bert 微调 #  预训练大语言模型的三种微调技术总结：\n fine-tuning  Fine-tuning 的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它。   parameter-efficient fine-tuning  PEFT 在尽可能减少所需的参数和计算资源的情况下，实现对预训练语言模型的有效微调。 3 种技术  蒸馏(distillation)，它由 Hinton 等人于 2015 年引入。该方法涉及训练一个较小的模型来模仿一个较大的预训练模型的行为。预训练模型生成“教师”预测结果，然后用于训练较小的“学生”模型。通过这样做，学生模型可以从较大模型的知识中学习，而无需存储所有参数。 适配器训练(adapter training)，它由 Houlsby 等人于 2019 年引入。适配器是添加到预训练模型中的小型神经网络，用于特定任务的微调。这些适配器只占原始模型大小的一小部分，这使得训练更快，内存需求更低。适配器可以针对多种任务进行训练，然后插入到预训练模型中以执行新任务。 渐进收缩(progressive shrinking)，它由 Kaplan 等人于 2020 年引入。这种技术涉及在 fine-tuning 期间逐渐减小预训练模型的大小。从一个大模型开始，逐渐减少参数的数量，直到达到所需的性能。这种方法可以产生比从头开始训练的模型性能更好的小型模型。     prompt-tuning  只修改模型的输入，不需要大量计算资源    参考：预训练大语言模型的三种微调技术总结：fine-tuning、parameter-efficient fine-tuning 和 prompt-tuning\n"}),e.add({id:11,href:"/study-ml/docs/basic/nlp/",title:"NLP",section:"第一部分 基础入门",content:"NLP #  NLP 的范式演进历程大体经历了这样四个阶段：\n 特征工程 → 深度学习 → 预训练+精调 → Prompt\n  预训练+精调范式：让预训练模型（PLM）去适应下游任务 Prompt 范式：让下游任务适应预训练模型（PLM）  Prompt：将下游任务的输入输出形式改造成预训练任务中的形式，即 MLM (Masked Language Model) 的形式    "}),e.add({id:12,href:"/study-ml/docs/basic/onnx/",title:"ONNX",section:"第一部分 基础入门",content:"ONNX #  Open Neural Network Exchange\n开放神经网络交换\n 是微软和 Facebook 提出用来表示深度学习模型的开放格式 定义了一组和环境，平台均无关的标准格式，来增强各种 AI 模型的可交互性 无论你使用何种训练框架训练模型（比如 TensorFlow/Pytorch/OneFlow/Paddle），在训练完毕后你都可以将这些框架的模型统一转换为 ONNX 这种统一的格式进行存储  "}),e.add({id:13,href:"/study-ml/docs/basic/ml/frame/pytorch/",title:"PyTorch",section:"AI 框架",content:"PyTorch #  pytorch/pytorch PyTorch is a Python package that provides two high-level features:\n Tensor computation (like NumPy) with strong GPU acceleration Deep neural networks built on a tape-based autograd system  "}),e.add({id:14,href:"/study-ml/docs/advanced/llm/",title:"LLM",section:"第二部分 进阶实战",content:"LLM（大型语言模型） #  "}),e.add({id:15,href:"/study-ml/docs/basic/lm/",title:"LM",section:"第一部分 基础入门",content:"Large Model（大模型） #  cv 大模型 #   facebookresearch/segment-anything  UX-Decoder/Segment-Everything-Everywhere-All-At-Once  SEEM: Segment Everything Everywhere All at Once   baaivision/Painter  Painter \u0026amp; SegGPT Series: Vision Foundation Models from BAAI    "}),e.add({id:16,href:"/study-ml/docs/basic/ml/dl/tutorial/",title:"教程",section:"深度学习",content:"教程 #  基础 #  《深度学习》(花书) #  MingchaoZhu/DeepLearning #  Python for《Deep Learning》，该书为《深度学习》(花书) 数学推导、原理剖析与源码级别代码实现\n 进阶 #   "})})()